apiVersion: apps/v1
kind: Deployment
metadata:
  name: zephyr-7b-alpha
spec:
  replicas: 1
  selector:
    matchLabels:
      app: zephyr-7b-alpha
  template:
    metadata:
      labels:
        app: zephyr-7b-alpha
    spec:
      #serviceAccountName: irsa-sa-s3
      nodeSelector:
        gpu-type: tesla-t4
      volumes:
        - name: model-storage
          persistentVolumeClaim:
            claimName: zephyr-7b-alpha-pvc
      initContainers:
        - name: init
          image: amazon/aws-cli
          command: ["sh", "-c", "aws s3 cp --recursive s3://k8s-model-zephyr/llm/deployment/zephyr-7b-alpha /data/zephyr-7b-alpha"]
          volumeMounts:
            - name: model-storage
              mountPath: /data
          resources:
            requests:
              cpu: "3"
      containers:
        - name: model
          image: ghcr.io/huggingface/text-generation-inference:latest
          command: ["text-generation-launcher", "--model-id", "HuggingFaceH4/zephyr-7b-alpha", "--quantize", "bitsandbytes", "--num-shard", "1", "--huggingface-hub-cache", "/usr/src/zephyr-7b-alpha", "--weights-cache-override", "/usr/src/zephyr-7b-alpha"]
          env:
            - name: HUGGINGFACE_OFFLINE
              value: "1"
            - name: PORT
              value: "8080"
          volumeMounts:
            - name: model-storage
              mountPath: /usr/src/
          resources:
            requests:
              cpu: "3"
              memory: "10Gi"
            limits:
              nvidia.com/gpu: 1
          ports:
            - containerPort: 8080
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: zephyr-7b-alpha-pvc
spec:
  accessModes:
    - ReadWriteOnce
  storageClassName: gp2
  resources:
    requests:
      storage: 100Gi
---
apiVersion: v1
kind: Service
metadata:
  name: zephyr-7b-alpha-service
spec:
  selector:
    app: zephyr-7b-alpha
  type: ClusterIP
  ports:
    - name: http
      port: 8080
      targetPort: 8080