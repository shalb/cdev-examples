{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Kubernetes cluster and deploy HF model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference article\n",
    "https://getindata.com/blog/deploy-open-source-llm-private-cluster-hugging-face-gke-autopilot/\n",
    "\n",
    "## Prerequisites\n",
    "- git-lfs installed to clone repo to s3\n",
    "- 100 GB of free space on local disk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing model files\n",
    "We would download model locally and then move it files to aws s3 bucket to be mounted by model container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: S3_BUCKET_NAME=k8s-model-zephyr\n",
      "env: REGION=eu-central-1\n",
      "env: HF_MODEL_PATH=HuggingFaceH4/zephyr-7b-beta\n",
      "env: HF_MODEL_NAME=zephyr-7b-beta\n",
      "env: LOCAL_DIRECTORY=/data-tst/home/voa/projects/k8s-model\n",
      "env: AWS_PROFILE=voatsap-cluster-dev\n"
     ]
    }
   ],
   "source": [
    "## Setting required env variables\n",
    "\n",
    "%env S3_BUCKET_NAME=k8s-model-zephyr\n",
    "%env REGION=eu-central-1\n",
    "%env HF_MODEL_PATH=HuggingFaceH4/zephyr-7b-beta\n",
    "%env HF_MODEL_NAME=zephyr-7b-beta\n",
    "%env LOCAL_DIRECTORY=/data-tst/home/voa/projects/k8s-model\n",
    "%env AWS_PROFILE voatsap-cluster-dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: 'git lfs clone' is deprecated and will not be updated\n",
      "          with new flags from 'git clone'\n",
      "\n",
      "'git clone' has been updated in upstream Git to have comparable\n",
      "speeds to 'git lfs clone'.\n",
      "Cloning into '/data-tst/home/voa/projects/k8s-model/wizard-7b-uncensored'...\n",
      "remote: Enumerating objects: 13, done.\u001b[K\n",
      "remote: Counting objects: 100% (13/13), done.\u001b[K\n",
      "remote: Compressing objects: 100% (12/12), done.\u001b[K\n",
      "remote: Total 13 (delta 0), reused 1 (delta 0), pack-reused 0\u001b[K\n",
      "Unpacking objects: 100% (13/13), 483.05 KiB | 2.10 MiB/s, done.\n",
      "make_bucket failed: s3://k8s-model-zephyr An error occurred (BucketAlreadyOwnedByYou) when calling the CreateBucket operation: Your previous request to create the named bucket succeeded and you already own it.\n",
      "upload: ../../../../../../../data-tst/home/voa/projects/k8s-model/wizard-7b-uncensored/.gitattributes to s3://k8s-model-zephyr/llm/deployment/wizard-7b-uncensored/.gitattributes\n",
      "upload: ../../../../../../../data-tst/home/voa/projects/k8s-model/wizard-7b-uncensored/added_tokens.json to s3://k8s-model-zephyr/llm/deployment/wizard-7b-uncensored/added_tokens.json\n",
      "upload: ../../../../../../../data-tst/home/voa/projects/k8s-model/wizard-7b-uncensored/generation_config.json to s3://k8s-model-zephyr/llm/deployment/wizard-7b-uncensored/generation_config.json\n",
      "upload: ../../../../../../../data-tst/home/voa/projects/k8s-model/wizard-7b-uncensored/special_tokens_map.json to s3://k8s-model-zephyr/llm/deployment/wizard-7b-uncensored/special_tokens_map.json\n",
      "upload: ../../../../../../../data-tst/home/voa/projects/k8s-model/wizard-7b-uncensored/config.json to s3://k8s-model-zephyr/llm/deployment/wizard-7b-uncensored/config.json\n",
      "upload: ../../../../../../../data-tst/home/voa/projects/k8s-model/wizard-7b-uncensored/README.md to s3://k8s-model-zephyr/llm/deployment/wizard-7b-uncensored/README.md\n",
      "upload: ../../../../../../../data-tst/home/voa/projects/k8s-model/wizard-7b-uncensored/quant_config.json to s3://k8s-model-zephyr/llm/deployment/wizard-7b-uncensored/quant_config.json\n",
      "upload: ../../../../../../../data-tst/home/voa/projects/k8s-model/wizard-7b-uncensored/tokenizer_config.json to s3://k8s-model-zephyr/llm/deployment/wizard-7b-uncensored/tokenizer_config.json\n",
      "upload: ../../../../../../../data-tst/home/voa/projects/k8s-model/wizard-7b-uncensored/tokenizer.json to s3://k8s-model-zephyr/llm/deployment/wizard-7b-uncensored/tokenizer.json\n",
      "upload: ../../../../../../../data-tst/home/voa/projects/k8s-model/wizard-7b-uncensored/tokenizer.model to s3://k8s-model-zephyr/llm/deployment/wizard-7b-uncensored/tokenizer.model\n",
      "upload: ../../../../../../../data-tst/home/voa/projects/k8s-model/wizard-7b-uncensored/model.safetensors to s3://k8s-model-zephyr/llm/deployment/wizard-7b-uncensored/model.safetensors\n"
     ]
    }
   ],
   "source": [
    "# clone model to local folder and upload to s3 bucket\n",
    "# this takes in my env(gigabit internet connection) ~9 min for clone and 6 min to upload\n",
    "\n",
    "!mkdir $LOCAL_DIRECTORY/$HF_MODEL_NAME\n",
    "!git lfs clone --depth=1 https://huggingface.co/$HF_MODEL_PATH $LOCAL_DIRECTORY/$HF_MODEL_NAME\n",
    "!aws s3 mb s3://$S3_BUCKET_NAME --region $REGION || true\n",
    "!aws s3 sync $LOCAL_DIRECTORY/$HF_MODEL_NAME s3://$S3_BUCKET_NAME/llm/deployment/$HF_MODEL_NAME --exclude \"*.git/*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://k8s-model-zephyr/llm/deployment/zephyr-7b-beta\n"
     ]
    }
   ],
   "source": [
    "# copy HF model to s3 bucket\n",
    "\n",
    "!echo s3://$S3_BUCKET_NAME/llm/deployment/$HF_MODEL_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing cluster.dev stack variables\n",
    "In cluster.dev folder there are 4 files:\n",
    "- `project.yaml` to define some global variables like region\n",
    "- `backend.yaml` required to set some state s3 bucket for cluster.dev and TF states\n",
    "- `stack-eks.yaml` file describing values for EKS cluster configuration with required node groups with GPU support, GPU types\n",
    "- `stack-model.yaml` Model variables required to deploy into EKS cluster\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bootstrap cluster\n",
    "!cd cluster.dev\n",
    "!cdev apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install nvidia drivers\n",
    "!kubectl apply -f https://raw.githubusercontent.com/NVIDIA/k8s-device-plugin/main/nvidia-device-plugin.yml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deploy model files\n",
    "!helm upgrade --install hfmodel  oci://registry-1.docker.io/shalb/huggingface-model -f ../helm/values.yaml\n",
    "\n",
    "# port forward model service\n",
    "!kubectl port-forward svc/hfmodel-$HF_MODEL_NAME  8081:8080\n",
    "\n",
    "!curl 127.0.0.1:8081/generate \\\n",
    "    -X POST \\\n",
    "    -d '{\"inputs\":\"Continue funny story: John decide to stick finger into outlet\",\"parameters\":{\"max_new_tokens\":1000}}' \\\n",
    "    -H 'Content-Type: application/json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chat UI\n",
    "helm install mongodb bitnami/mongodb\n",
    "kubectl get secret --namespace default mongodb -o jsonpath=\"{.data.mongodb-root-password}\" | base64 -d\n",
    "kubectl apply -f ../kubernetes/chat-ui.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monitoring\n",
    "\n",
    "https://aws.amazon.com/blogs/machine-learning/enable-pod-based-gpu-metrics-in-amazon-cloudwatch/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curl https://raw.githubusercontent.com/NVIDIA/dcgm-exporter/main/etc/dcp-metrics-included.csv > /tmp/dcgm-metrics.csv\n",
    "\n",
    "kubectl create namespace gpu-operator\n",
    "kubectl create configmap metrics-config -n gpu-operator --from-file=/tmp/dcgm-metrics.csv\n",
    "\n",
    "helm install --wait --generate-name -n gpu-operator --create-namespace nvidia/gpu-operator \\\n",
    "--set dcgmExporter.config.name=metrics-config \\\n",
    "--set toolkit.enabled=false\n",
    "\n",
    "# Install prometheus stack\n",
    "helm repo add prometheus-community https://prometheus-community.github.io/helm-charts\n",
    "helm inspect values prometheus-community/kube-prometheus-stack > /tmp/kube-prometheus-stack.values\n",
    "\n",
    "sed -i '/serviceMonitorSelectorNilUsesHelmValues/ s/true/false/' /tmp/kube-prometheus-stack.values\n",
    "yq eval '.prometheus.prometheusSpec.additionalScrapeConfigs += [{\"job_name\": \"gpu-metrics\", \"scrape_interval\": \"1s\", \"metrics_path\": \"/metrics\", \"scheme\": \"http\", \"kubernetes_sd_configs\": [{\"role\": \"endpoints\", \"namespaces\": {\"names\": [\"gpu-operator\"]}}], \"relabel_configs\": [{\"source_labels\": [\"__meta_kubernetes_pod_node_name\"], \"action\": \"replace\", \"target_label\": \"kubernetes_node\"}]}]' /tmp/kube-prometheus-stack.values -i\n",
    "\n",
    "# get admin password for Grafana\n",
    "kubectl -n prometheus get secret $(kubectl -n prometheus get secrets | grep grafana | cut -d ' ' -f 1) -o jsonpath=\"{.data.admin-password}\" | base64 --decode ; echo\n",
    "\n",
    "# port forward Grafana\n",
    "kubectl port-forward -n prometheus svc/$(kubectl -n prometheus get svc | grep grafana | cut -d ' ' -f 1) 8080:80 &\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
